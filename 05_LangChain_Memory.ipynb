{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_= load_dotenv(find_dotenv())\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ajeettiwari/Documents/AAIEE/LLM/llmapp/lib/python3.9/site-packages/langchain_community/llms/openai.py:253: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain_community.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/Users/ajeettiwari/Documents/AAIEE/LLM/llmapp/lib/python3.9/site-packages/langchain_community/llms/openai.py:1076: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain_community.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI\n",
    "llm = OpenAI(openai_api_key=openai_api_key, model_name=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buffer Memory\n",
    "\n",
    "ConversationBufferMemory keeps a list of chat maeesages in buffer and passes them into prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/90/s9rwqz1j6ng3m5ghghjb6rp80000gp/T/ipykernel_75926/3892269499.py:22: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  conversation_chain = LLMChain(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How are you doing today?\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Define LLM with the new OpenAI API\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# Define the prompt template\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate.from_template(\"You are a nice chatbot having a conversation with a human.\"),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define memory\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# Define the conversation chain\n",
    "conversation_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "# Run the conversation\n",
    "response = conversation_chain.invoke({\"question\": \"Hi there!\"})\n",
    "print(response[\"text\"])  # Output response text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'My name is Ajeet and I have moved 33 times.',\n",
       " 'chat_history': [HumanMessage(content='Hi there!', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello! How are you doing today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='My name is Bappy and I have moved 33 times.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Nice to meet you, Bappy! Moving 33 times must have given you a lot of interesting experiences. What's the reason behind moving so many times?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='My name is Ajeet and I have moved 33 times.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Nice to meet you, Ajeet! Moving 33 times is quite a lot. What has been the most challenging part of moving so frequently?', additional_kwargs={}, response_metadata={})],\n",
       " 'text': 'Nice to meet you, Ajeet! Moving 33 times is quite a lot. What has been the most challenging part of moving so frequently?'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain({\"question\":\"My name is Ajeet and I have moved 33 times.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'If my average moving distance is 1000 miles, how many miles have I moved in total?',\n",
       " 'chat_history': [HumanMessage(content='Hi there!', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello! How are you doing today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='My name is Bappy and I have moved 33 times.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Nice to meet you, Bappy! Moving 33 times must have given you a lot of interesting experiences. What's the reason behind moving so many times?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='My name is Ajeet and I have moved 33 times.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Nice to meet you, Ajeet! Moving 33 times is quite a lot. What has been the most challenging part of moving so frequently?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='If my average moving distance is 1000 miles, how many miles have I moved in total?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"If you have moved 33 times with an average distance of 1000 miles each time, then you have moved a total of 33,000 miles. That's quite a journey!\", additional_kwargs={}, response_metadata={})],\n",
       " 'text': \"If you have moved 33 times with an average distance of 1000 miles each time, then you have moved a total of 33,000 miles. That's quite a journey!\"}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain({\"question\":\"If my average moving distance is 1000 miles, how many miles have I moved in total?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Do you remenber my name?',\n",
       " 'chat_history': [HumanMessage(content='Hi there!', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello! How are you doing today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='My name is Bappy and I have moved 33 times.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Nice to meet you, Bappy! Moving 33 times must have given you a lot of interesting experiences. What's the reason behind moving so many times?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='My name is Ajeet and I have moved 33 times.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Nice to meet you, Ajeet! Moving 33 times is quite a lot. What has been the most challenging part of moving so frequently?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='If my average moving distance is 1000 miles, how many miles have I moved in total?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"If you have moved 33 times with an average distance of 1000 miles each time, then you have moved a total of 33,000 miles. That's quite a journey!\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Do you remenber my name?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Yes, your name is Ajeet. How can I assist you today, Ajeet?', additional_kwargs={}, response_metadata={})],\n",
       " 'text': 'Yes, your name is Ajeet. How can I assist you today, Ajeet?'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain({\"question\":\"Do you remenber my name?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Hi there!', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello! How are you doing today?', additional_kwargs={}, response_metadata={}), HumanMessage(content='My name is Bappy and I have moved 33 times.', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Nice to meet you, Bappy! Moving 33 times must have given you a lot of interesting experiences. What's the reason behind moving so many times?\", additional_kwargs={}, response_metadata={}), HumanMessage(content='My name is Ajeet and I have moved 33 times.', additional_kwargs={}, response_metadata={}), AIMessage(content='Nice to meet you, Ajeet! Moving 33 times is quite a lot. What has been the most challenging part of moving so frequently?', additional_kwargs={}, response_metadata={}), HumanMessage(content='If my average moving distance is 1000 miles, how many miles have I moved in total?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"If you have moved 33 times with an average distance of 1000 miles each time, then you have moved a total of 33,000 miles. That's quite a journey!\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Do you remenber my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='Yes, your name is Ajeet. How can I assist you today, Ajeet?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversation Buffer Window Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the previous one , but you can limit the numberof conversational exchanges stored in memory. For example , you can set it so it only remembers the last 3 questions and answers of the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "window_memory = ConversationBufferWindowMemory(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/90/s9rwqz1j6ng3m5ghghjb6rp80000gp/T/ipykernel_75926/3058449323.py:1: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  conversation_chain = ConversationChain(\n"
     ]
    }
   ],
   "source": [
    "conversation_chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=window_memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi there!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Hi there!',\n",
       " 'history': '',\n",
       " 'response': 'Hello! How can I assist you today?'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain({\"input\": \"Hi there!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI: Hello! How can I assist you today?\n",
      "Human: My favourite color is blue.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'My favourite color is blue.',\n",
       " 'history': 'Human: Hi there!\\nAI: Hello! How can I assist you today?',\n",
       " 'response': \"Blue is a great choice! It's often associated with calmness, tranquility, and stability. Do you have a specific shade of blue that you prefer, like navy blue, sky blue, or royal blue?\"}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain({\"input\": \"My favourite color is blue.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI: Hello! How can I assist you today?\n",
      "Human: My favourite color is blue.\n",
      "AI: Blue is a great choice! It's often associated with calmness, tranquility, and stability. Do you have a specific shade of blue that you prefer, like navy blue, sky blue, or royal blue?\n",
      "Human: My favourite animals are dogs.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'My favourite animals are dogs.',\n",
       " 'history': \"Human: Hi there!\\nAI: Hello! How can I assist you today?\\nHuman: My favourite color is blue.\\nAI: Blue is a great choice! It's often associated with calmness, tranquility, and stability. Do you have a specific shade of blue that you prefer, like navy blue, sky blue, or royal blue?\",\n",
       " 'response': 'Dogs are wonderful animals! They are known for their loyalty, companionship, and diverse breeds. Do you have a favorite breed of dog, such as a Labrador Retriever, German Shepherd, or Golden Retriever?'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " conversation_chain({\"input\": \"My favourite animals are dogs.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI: Hello! How can I assist you today?\n",
      "Human: My favourite color is blue.\n",
      "AI: Blue is a great choice! It's often associated with calmness, tranquility, and stability. Do you have a specific shade of blue that you prefer, like navy blue, sky blue, or royal blue?\n",
      "Human: My favourite animals are dogs.\n",
      "AI: Dogs are wonderful animals! They are known for their loyalty, companionship, and diverse breeds. Do you have a favorite breed of dog, such as a Labrador Retriever, German Shepherd, or Golden Retriever?\n",
      "Human: My favourite food is pizza.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'My favourite food is pizza.',\n",
       " 'history': \"Human: Hi there!\\nAI: Hello! How can I assist you today?\\nHuman: My favourite color is blue.\\nAI: Blue is a great choice! It's often associated with calmness, tranquility, and stability. Do you have a specific shade of blue that you prefer, like navy blue, sky blue, or royal blue?\\nHuman: My favourite animals are dogs.\\nAI: Dogs are wonderful animals! They are known for their loyalty, companionship, and diverse breeds. Do you have a favorite breed of dog, such as a Labrador Retriever, German Shepherd, or Golden Retriever?\",\n",
       " 'response': 'Pizza is a popular choice! There are so many delicious toppings to choose from, like pepperoni, mushrooms, peppers, and more. Do you have a favorite type of pizza crust, like thin crust, deep dish, or stuffed crust?'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain({\"input\": \"My favourite food is pizza.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: My favourite animals are dogs.\n",
      "AI: Dogs are wonderful animals! They are known for their loyalty, companionship, and diverse breeds. Do you have a favorite breed of dog, such as a Labrador Retriever, German Shepherd, or Golden Retriever?\n",
      "Human: My favourite food is pizza.\n",
      "AI: Pizza is a popular choice! There are so many delicious toppings to choose from, like pepperoni, mushrooms, peppers, and more. Do you have a favorite type of pizza crust, like thin crust, deep dish, or stuffed crust?\n",
      "Human: What is my favourite color?\n",
      "AI: Your favorite color is blue.\n",
      "Human: My favourite sport is basketball.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'My favourite sport is basketball.',\n",
       " 'history': 'Human: My favourite animals are dogs.\\nAI: Dogs are wonderful animals! They are known for their loyalty, companionship, and diverse breeds. Do you have a favorite breed of dog, such as a Labrador Retriever, German Shepherd, or Golden Retriever?\\nHuman: My favourite food is pizza.\\nAI: Pizza is a popular choice! There are so many delicious toppings to choose from, like pepperoni, mushrooms, peppers, and more. Do you have a favorite type of pizza crust, like thin crust, deep dish, or stuffed crust?\\nHuman: What is my favourite color?\\nAI: Your favorite color is blue.',\n",
       " 'response': ': Basketball is a fast-paced and exciting sport! Do you have a favorite team or player that you like to watch?'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain({\"input\":\"My favourite sport is basketball.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: My favourite food is pizza.\n",
      "AI: Pizza is a popular choice! There are so many delicious toppings to choose from, like pepperoni, mushrooms, peppers, and more. Do you have a favorite type of pizza crust, like thin crust, deep dish, or stuffed crust?\n",
      "Human: What is my favourite color?\n",
      "AI: Your favorite color is blue.\n",
      "Human: My favourite sport is basketball.\n",
      "AI: : Basketball is a fast-paced and exciting sport! Do you have a favorite team or player that you like to watch?\n",
      "Human: What is my favourite color?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is my favourite color?',\n",
       " 'history': 'Human: My favourite food is pizza.\\nAI: Pizza is a popular choice! There are so many delicious toppings to choose from, like pepperoni, mushrooms, peppers, and more. Do you have a favorite type of pizza crust, like thin crust, deep dish, or stuffed crust?\\nHuman: What is my favourite color?\\nAI: Your favorite color is blue.\\nHuman: My favourite sport is basketball.\\nAI: : Basketball is a fast-paced and exciting sport! Do you have a favorite team or player that you like to watch?',\n",
       " 'response': \"I'm sorry, I don't have that information. What is your favorite color?\"}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain({\"input\":\"What is my favourite color?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Message History\n",
    "\n",
    "Save list of chat messages and then fetch them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  langchain.memory import ChatMessageHistory\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "\n",
    "history.add_user_message(\"hi!\")\n",
    "\n",
    "history.add_ai_message(\"whats up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi!', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='whats up?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.messages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmapp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
